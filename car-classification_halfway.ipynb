{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":300657,"sourceType":"datasetVersion","datasetId":124720}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, random, math, json\nimport numpy as np\nimport scipy.io\nimport torch, torch.nn as nn\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\nimport timm\nfrom torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score\n\n\n# Kaggle paths\nDATA_ROOT = \"/kaggle/input/stanford-cars-dataset\"\nTRAIN_DIR = os.path.join(DATA_ROOT, \"cars_train/cars_train\")\nTEST_DIR  = os.path.join(DATA_ROOT, \"cars_test/cars_test\")     # (labels usually not available)\nDEVKIT    = os.path.join(DATA_ROOT, \"car_devkit\", \"devkit\")\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n\nIMAGENET_MEAN=[0.485,0.456,0.406]; IMAGENET_STD=[0.229,0.224,0.225]\nNUM_WORKERS = 2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T03:08:27.305205Z","iopub.execute_input":"2025-09-16T03:08:27.305790Z","iopub.status.idle":"2025-09-16T03:08:48.394599Z","shell.execute_reply.started":"2025-09-16T03:08:27.305762Z","shell.execute_reply":"2025-09-16T03:08:48.393948Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Meta\nmeta = scipy.io.loadmat(os.path.join(DEVKIT, \"cars_meta.mat\"))\n\n# len = 196\nCLASS_NAMES = [c[0] for c in meta[\"class_names\"][0]]\n\nprint(f\"Number of Classes: {len(CLASS_NAMES)}\")\n\n\n# Train annotations (fname, class (1..196), bbox, etc.)\ntrain_annos = scipy.io.loadmat(os.path.join(DEVKIT, \"cars_train_annos.mat\"))[\"annotations\"][0]\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T03:09:30.164642Z","iopub.execute_input":"2025-09-16T03:09:30.165446Z","iopub.status.idle":"2025-09-16T03:09:30.341518Z","shell.execute_reply.started":"2025-09-16T03:09:30.165416Z","shell.execute_reply":"2025-09-16T03:09:30.340841Z"}},"outputs":[{"name":"stdout","text":"Number of Classes: 196\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"class StanfordCars(Dataset):\n    \"\"\"Uses .mat annotations; returns (image_tensor, class_id[0..195]).\"\"\"\n    def __init__(self, img_dir, annos, transform=None, use_bbox=False):\n        self.img_dir = img_dir\n        self.annos = annos\n        self.transform = transform\n        self.use_bbox = use_bbox\n\n    def __len__(self):\n        return len(self.annos)\n\n    def __getitem__(self, i):\n        a = self.annos[i]\n        fname = str(a[\"fname\"][0])\n        y = int(a[\"class\"][0,0]) - 1  # 0..195\n        path = os.path.join(self.img_dir, fname)\n        img = Image.open(path).convert(\"RGB\")\n\n        if self.use_bbox:\n            # optional cropping to car bbox for stronger fine-grained signal\n            x1, y1, x2, y2 = [int(a[k][0,0]) for k in (\"bbox_x1\",\"bbox_y1\",\"bbox_x2\",\"bbox_y2\")]\n            img = img.crop((x1, y1, x2, y2))\n\n        if self.transform:\n            img = self.transform(img)\n            \n        return img, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T03:09:39.029702Z","iopub.execute_input":"2025-09-16T03:09:39.030399Z","iopub.status.idle":"2025-09-16T03:09:39.036140Z","shell.execute_reply.started":"2025-09-16T03:09:39.030372Z","shell.execute_reply":"2025-09-16T03:09:39.035570Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_tf = transforms.Compose([\n    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(0.2,0.2,0.2,0.05),\n    transforms.ToTensor(),\n    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n])\nval_tf = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T03:09:59.411455Z","iopub.execute_input":"2025-09-16T03:09:59.411708Z","iopub.status.idle":"2025-09-16T03:09:59.416416Z","shell.execute_reply.started":"2025-09-16T03:09:59.411691Z","shell.execute_reply":"2025-09-16T03:09:59.415642Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Build base datasets after transforms are defined\ntrain_base = StanfordCars(TRAIN_DIR, train_annos, transform=train_tf, use_bbox=False)\nval_base = StanfordCars(TRAIN_DIR, train_annos, transform=val_tf,   use_bbox=False)\n\n# Stratified split from the same annotation order\nlabels = np.array([int(a[\"class\"][0,0])-1 for a in train_annos])\nindices = np.arange(len(train_annos))\n\ntrain_idx, val_idx = train_test_split(indices, test_size=0.15, stratify=labels, random_state=42)\n\ntrain_ds = Subset(train_base, train_idx)\nval_ds = Subset(val_base, val_idx)\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n\n# batch of images: shape (B, C, H, W) = (32, 3, 224, 224).\nxb, yb = next(iter(train_loader))\n\n# average pixel intensity of that channel after preprocessing.\nprint(\"Batch mean:\", xb.mean(dim=(0,2,3)).tolist(), \"std:\", xb.std(dim=(0,2,3)).tolist())\nprint(\"Train/Val sizes:\", len(train_ds), len(val_ds), \"Num classes:\", len(CLASS_NAMES))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T03:10:16.277737Z","iopub.execute_input":"2025-09-16T03:10:16.278392Z","iopub.status.idle":"2025-09-16T03:10:18.523989Z","shell.execute_reply.started":"2025-09-16T03:10:16.278367Z","shell.execute_reply":"2025-09-16T03:10:18.523148Z"}},"outputs":[{"name":"stdout","text":"Batch mean: [-0.2167356312274933, -0.17636573314666748, -0.03354310244321823] std: [1.2685903310775757, 1.2715939283370972, 1.2584930658340454]\nTrain/Val sizes: 6922 1222 Num classes: 196\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def train_model(epochs_frozen=3, epochs_full=17, arch=\"timm:convnext_tiny\",\n                lr_head=3e-4, lr_full=1e-4, out_dir=\"/kaggle/working/models\"):\n    os.makedirs(out_dir, exist_ok=True)\n    num_classes = len(CLASS_NAMES)\n    model = timm.create_model(\"timm:convnext_tiny\", pretrained=True, num_classes=num_classes).to(DEVICE)\n\n    # Metrics setup\n    acc_metric = MulticlassAccuracy(num_classes=num_classes).to(DEVICE)\n    f1_metric  = MulticlassF1Score(num_classes=num_classes, average=\"macro\").to(DEVICE)\n    crit = nn.CrossEntropyLoss()\n\n    # Stage A: freeze backbone (train only head)\n    for n,p in model.named_parameters():\n        if not any(k in n for k in (\"head\",\"classifier\")):\n            p.requires_grad = False\n    opt = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n                            lr=lr_head, weight_decay=1e-4)\n    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs_frozen)\n    scaler = torch.amp.GradScaler('cuda')\n\n    best_f1 = 0.0\n    def run_epoch(train=True):\n        loader = train_loader if train else val_loader\n        model.train() if train else model.eval()\n        total = correct = 0\n        acc_metric.reset()\n        f1_metric.reset()\n        running_loss = 0.0\n        for xb,yb in loader:\n            xb,yb = xb.to(DEVICE), yb.to(DEVICE)\n            if train:\n                opt.zero_grad(set_to_none=True)\n                with torch.amp.autocast('cuda'):\n                    logits = model(xb)\n                    loss = crit(logits, yb)\n                scaler.scale(loss).backward()\n                scaler.step(opt)\n                scaler.update()\n                running_loss += loss.item() * xb.size(0)\n            else:\n                with torch.no_grad():\n                    logits = model(xb)\n            acc_metric.update(logits, yb)\n            f1_metric.update(logits, yb)\n            correct += (logits.argmax(1)==yb).sum().item()\n            total += yb.numel()\n        avg_loss = running_loss / max(1, (len(loader.dataset) if train else len(loader.dataset)))\n        return correct/total, acc_metric.compute().item(), f1_metric.compute().item(), avg_loss\n\n    # Stage A\n    for ep in range(1, epochs_frozen+1):\n        tr_acc, _, _, tr_loss = run_epoch(True)\n        va_acc, va_acc_m, va_f1, _ = run_epoch(False)\n        print(f\"[A] E{ep:02d} train_acc={tr_acc:.3f} val_acc={va_acc:.3f} val_f1={va_f1:.3f}\")\n        if va_f1 > best_f1:\n            best_f1 = va_f1\n            torch.save({\"model\": model.state_dict(), \"classes\": CLASS_NAMES, \"arch\": arch},\n                       os.path.join(out_dir, \"best.pt\"))\n        sched.step()\n\n    # Stage B: unfreeze all, lower LR\n    for p in model.parameters(): \n        p.requires_grad = True\n    opt = torch.optim.AdamW(model.parameters(), lr=lr_full, weight_decay=1e-4)\n    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs_full)\n    scaler = torch.cuda.amp.GradScaler()\n\n    for ep in range(1, epochs_full+1):\n        tr_acc, _, _, tr_loss = run_epoch(True)\n        va_acc, va_acc_m, va_f1, _ = run_epoch(False)\n        if va_f1 > best_f1:\n            best_f1 = va_f1\n            torch.save({\"model\": model.state_dict(), \"classes\": CLASS_NAMES, \"arch\": arch},\n                       os.path.join(out_dir, \"best.pt\"))\n        print(f\"[B] E{ep:02d} train_acc={tr_acc:.3f} val_acc={va_acc:.3f} val_f1={va_f1:.3f} (best_f1={best_f1:.3f})\")\n        sched.step()\n\n    print(\"Saved:\", os.path.join(out_dir, \"best.pt\"))\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T03:10:45.689903Z","iopub.execute_input":"2025-09-16T03:10:45.690715Z","iopub.status.idle":"2025-09-16T03:10:45.703236Z","shell.execute_reply.started":"2025-09-16T03:10:45.690684Z","shell.execute_reply":"2025-09-16T03:10:45.702617Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"model = train_model(\n    epochs_frozen=3,   # 3â€“5 is fine\n    epochs_full=17,    # total ~20 epochs\n    arch=\"timm:convnext_tiny\",\n    lr_head=3e-4,\n    lr_full=1e-4\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T03:10:49.247355Z","iopub.execute_input":"2025-09-16T03:10:49.247638Z","iopub.status.idle":"2025-09-16T03:33:04.634026Z","shell.execute_reply.started":"2025-09-16T03:10:49.247617Z","shell.execute_reply":"2025-09-16T03:33:04.633131Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5f67cc96048451d8ecd4dbe4b4f5244"}},"metadata":{}},{"name":"stdout","text":"[A] E01 train_acc=0.132 val_acc=0.243 val_f1=0.203\n[A] E02 train_acc=0.366 val_acc=0.337 val_f1=0.313\n[A] E03 train_acc=0.481 val_acc=0.402 val_f1=0.382\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/584311182.py:67: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"[B] E01 train_acc=0.538 val_acc=0.718 val_f1=0.703 (best_f1=0.703)\n[B] E02 train_acc=0.894 val_acc=0.804 val_f1=0.798 (best_f1=0.798)\n[B] E03 train_acc=0.966 val_acc=0.818 val_f1=0.810 (best_f1=0.810)\n[B] E04 train_acc=0.987 val_acc=0.849 val_f1=0.844 (best_f1=0.844)\n[B] E05 train_acc=0.993 val_acc=0.843 val_f1=0.837 (best_f1=0.844)\n[B] E06 train_acc=0.994 val_acc=0.842 val_f1=0.835 (best_f1=0.844)\n[B] E07 train_acc=0.993 val_acc=0.836 val_f1=0.832 (best_f1=0.844)\n[B] E08 train_acc=0.991 val_acc=0.859 val_f1=0.853 (best_f1=0.853)\n[B] E09 train_acc=0.997 val_acc=0.874 val_f1=0.869 (best_f1=0.869)\n[B] E10 train_acc=0.999 val_acc=0.885 val_f1=0.881 (best_f1=0.881)\n[B] E11 train_acc=0.999 val_acc=0.891 val_f1=0.887 (best_f1=0.887)\n[B] E12 train_acc=0.998 val_acc=0.885 val_f1=0.881 (best_f1=0.887)\n[B] E13 train_acc=0.999 val_acc=0.889 val_f1=0.885 (best_f1=0.887)\n[B] E14 train_acc=0.999 val_acc=0.892 val_f1=0.889 (best_f1=0.889)\n[B] E15 train_acc=0.999 val_acc=0.894 val_f1=0.892 (best_f1=0.892)\n[B] E16 train_acc=0.999 val_acc=0.894 val_f1=0.891 (best_f1=0.892)\n[B] E17 train_acc=0.999 val_acc=0.893 val_f1=0.890 (best_f1=0.892)\nSaved: /kaggle/working/models/best.pt\n","output_type":"stream"}],"execution_count":7}]}